{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared_home/vdeshpande/miniconda3/envs/long_seq/lib/python3.9/site-packages/tqdm-4.66.1-py3.9.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-20 14:12:34,075] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import datasets\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "#from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "import wandb\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import (\n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    get_peft_model,\n",
    "    PromptTuningInit,\n",
    "    PromptTuningConfig,\n",
    "    TaskType,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "from loguru import logger\n",
    "\n",
    "import sys\n",
    "sys.path.append('./../scripts')\n",
    "import data_utils \n",
    "import finetuning_seq2seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = finetuning_seq2seq.parse_args()\n",
    "args.peft_method = \"lora\"\n",
    "args.task_type = \"classification\"\n",
    "args.dataset_name = \"super_glue\"\n",
    "args.dataset_config_name = \"boolq\"\n",
    "args.source_prefix = \"\"\n",
    "args.num_beams = 1\n",
    "accelerator = Accelerator()\n",
    "model, tokenizer, config = finetuning_seq2seq.get_model(args)\n",
    "\n",
    "#\n",
    "args, model, tokenizer, accelerator, logger, train_dataloader, eval_dataloader = data_utils.preprocess_data(\n",
    "        args=args,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        accelerator=accelerator,\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "false\n",
      "['false', 'true']\n",
      "false\n",
      "['false', 'true']\n",
      "false\n",
      "['false', 'true']\n",
      "true\n",
      "['false', 'true']\n",
      "1\n",
      "true\n",
      "['false', 'true']\n",
      "true\n",
      "['false', 'true']\n",
      "true\n",
      "['false', 'true']\n",
      "true\n",
      "['false', 'true']\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-20 14:25:36.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1m{'accuracy': 66.6667}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "['false', 'true']\n",
      "true\n",
      "['false', 'true']\n",
      "false\n",
      "['false', 'true']\n",
      "false\n",
      "['false', 'true']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "metric = evaluate.load(args.dataset_name, args.dataset_config_name)\n",
    "gen_kwargs = {\n",
    "    \"max_length\": args.val_max_target_length if args.val_max_target_length else args.max_target_length,\n",
    "    \"min_length\": 1,\n",
    "    \"num_beams\": args.num_beams,\n",
    "}\n",
    "for step_eval, batch in enumerate(eval_dataloader):\n",
    "    print(step_eval)\n",
    "    with torch.no_grad():\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        generated_tokens = unwrapped_model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            **gen_kwargs,\n",
    "        )\n",
    "\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = batch[\"labels\"]\n",
    "        if not args.pad_to_max_length:\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "\n",
    "        generated_tokens, labels = accelerator.gather_for_metrics((generated_tokens, labels))\n",
    "        generated_tokens = generated_tokens.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        if args.ignore_pad_token_for_loss:\n",
    "            # Replace -100 in the labels as we can't decode them.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_preds, decoded_labels = data_utils.postprocess_classification(decoded_preds, decoded_labels, args.dataset_config_name)\n",
    "\n",
    "        metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "        )\n",
    "\n",
    "    if (step_eval > 1):\n",
    "        break\n",
    "\n",
    "result = metric.compute()#use_stemmer=True)\n",
    "result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_labels = tokenizer.batch_decode(labels)\n",
    "str_preds = tokenizer.batch_decode(generated_tokens)\n",
    "\n",
    "print(str_labels)\n",
    "print(str_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_classification_(preds, labels, dataset_config_name=None):\n",
    "\n",
    "\n",
    "    #\n",
    "    pred_ids, label_ids = [], []\n",
    "    for idx, pred in enumerate(preds):\n",
    "        pred_id = string_label_to_class_id(\n",
    "            string_label=pred.lower(), \n",
    "            label_classes=label_names_mapping[dataset_config_name]\n",
    "            )\n",
    "        label_id = string_label_to_class_id(\n",
    "            string_label=labels[idx].lower(), \n",
    "            label_classes=label_names_mapping[dataset_config_name]\n",
    "            )\n",
    "        pred_ids.append(pred_id)\n",
    "        label_ids.append(label_id)\n",
    "    \n",
    "    return pred_ids, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds, decoded_labels = data_utils.postprocess_classification(str_preds, str_labels, args.dataset_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long_seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
