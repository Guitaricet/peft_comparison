{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/public/vlialin/miniconda3/envs/peft_comparison/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pprint import pformat\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import load_dataset\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "from loguru import logger\n",
    "\n",
    "from adapters import LlamaAdapterModel, T5AdapterModel\n",
    "\n",
    "import peft_comparison\n",
    "import peft_comparison.text2text_utils\n",
    "import peft_comparison.mappings\n",
    "from peft_comparison.collation import DataCollatorForSeq2SeqWithMetadata, DataCollatorForCausalLMWithMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5AdapterModel.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter(\"adapter\", config=\"lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters.lora import LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.encoder.block[0].layer[0].SelfAttention.k.loras.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'adapters.lora.LoRA'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.0735e-02,  8.0785e-05, -1.6535e-02,  ...,  3.2640e-02,\n",
       "          3.4925e-02, -2.3914e-02],\n",
       "        [-3.5664e-02,  2.1651e-02,  3.7073e-02,  ..., -2.1957e-02,\n",
       "         -3.5951e-02,  3.2999e-02],\n",
       "        [ 2.1858e-02, -3.3383e-02, -3.6094e-02,  ..., -3.5184e-02,\n",
       "          2.3945e-02,  5.1780e-03],\n",
       "        ...,\n",
       "        [ 4.3645e-02,  1.0507e-02,  3.6210e-02,  ...,  3.8441e-02,\n",
       "          2.1456e-02,  2.3936e-02],\n",
       "        [-3.3017e-02,  1.5436e-02, -2.4072e-02,  ..., -2.7966e-02,\n",
       "         -3.3491e-03, -1.6739e-02],\n",
       "        [ 1.9498e-03,  2.1769e-02, -4.0025e-02,  ...,  5.6638e-03,\n",
       "          1.0099e-02,  2.1497e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_layer = model.transformer.encoder.block[0].layer[0].SelfAttention.q.loras[\"adapter\"]\n",
    "print(type(lora_layer))\n",
    "lora_layer.lora_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'attn_matrices',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'com',\n",
       " 'com_inv',\n",
       " 'compile',\n",
       " 'composition_mode',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'lora_A',\n",
       " 'lora_B',\n",
       " 'lora_alpha',\n",
       " 'lora_dropout',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'r',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'scaling',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'use_gating',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lora_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5AdapterModel(\n",
       "  (transformer): T5Model(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5StackWithAdapters(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttentionWithAdapters(\n",
       "              (SelfAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (1): T5LayerFFWithAdapters(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(\n",
       "                  in_features=512, out_features=2048, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (wo): Linear(\n",
       "                  in_features=2048, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttentionWithAdapters(\n",
       "              (SelfAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (1): T5LayerFFWithAdapters(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(\n",
       "                  in_features=512, out_features=2048, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (wo): Linear(\n",
       "                  in_features=2048, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (invertible_adapters): ModuleDict()\n",
       "    )\n",
       "    (decoder): T5StackWithAdapters(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttentionWithAdapters(\n",
       "              (SelfAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (1): T5LayerCrossAttentionWithAdapters(\n",
       "              (EncDecAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (2): T5LayerFFWithAdapters(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(\n",
       "                  in_features=512, out_features=2048, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (wo): Linear(\n",
       "                  in_features=2048, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttentionWithAdapters(\n",
       "              (SelfAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (1): T5LayerCrossAttentionWithAdapters(\n",
       "              (EncDecAttention): T5AttentionWithAdapters(\n",
       "                (q): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (k): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (v): Linear(\n",
       "                  in_features=512, out_features=512, bias=False\n",
       "                  (loras): ModuleDict(\n",
       "                    (adapter): LoRA(512, 8, 512)\n",
       "                  )\n",
       "                )\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (prefix_tuning): PrefixTuningShim(\n",
       "                  (prefix_gates): ModuleDict()\n",
       "                  (pool): PrefixTuningPool(\n",
       "                    (prefix_tunings): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "            (2): T5LayerFFWithAdapters(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(\n",
       "                  in_features=512, out_features=2048, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (wo): Linear(\n",
       "                  in_features=2048, out_features=512, bias=False\n",
       "                  (loras): ModuleDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = peft.LoraConfig(\n",
    "    target_modules=[\"k\", \"q\", \"v\", \"o\", \"wi\", \"wo\"],\n",
    ")\n",
    "model = peft.get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" not in name and param.requires_grad:\n",
    "        raise ValueError(f\"Parameter {name} requires grad but is not in LoRA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_param_names = [n for n, p in model.named_parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.lora_B.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.lora_A.default.weight',\n",
       " 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.lora_B.default.weight']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft_comparison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
