{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/public/vdeshpan/miniconda3/envs/peft_comparison_v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pprint import pformat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import load_dataset\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "from loguru import logger\n",
    "\n",
    "import scripts\n",
    "from adapters.models.llama.adapter_model import LlamaAdapterModel\n",
    "import peft_comparison\n",
    "import peft_comparison.text2text_utils\n",
    "import peft_comparison.mappings\n",
    "from peft_comparison.collation import DataCollatorForSeq2SeqWithMetadata, DataCollatorForCausalLMWithMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding = \"max_length\"\n",
    "truncation = True\n",
    "\n",
    "source_prefix = \"\"\n",
    "max_source_length = 512\n",
    "decoder_only = True\n",
    "max_target_length = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First we tokenize all the texts.\n",
    "def preprocess_function(examples, is_eval=False, decoder_only=False):\n",
    "    inputs = examples[\"source_text\"]\n",
    "    targets = examples[\"target_text\"]\n",
    "    inputs = [source_prefix + inp for inp in inputs]\n",
    "\n",
    "    if not decoder_only:\n",
    "        model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "        labels = tokenizer(text_target=targets, max_length=max_target_length, padding=padding, truncation=True)\n",
    "        if padding == \"max_length\":\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        if is_eval:\n",
    "            model_inputs[\"metadata\"] = [{\"targets\": t} for t in targets]\n",
    "\n",
    "    else:\n",
    "        if is_eval:\n",
    "            model_inputs = tokenizer(inputs, max_length=max_source_length, padding=False, truncation=True)\n",
    "        else:\n",
    "            model_inputs = tokenizer(inputs, targets, max_length=max_source_length, padding=False, truncation=True)\n",
    "\n",
    "        # @NOTE: we can set labels to input_ids because the token shifting is taken care of in the modeling_llaama file\n",
    "        model_inputs[\"labels\"] = model_inputs[\"input_ids\"]\n",
    "        if is_eval:\n",
    "            input_wo_label = tokenizer(inputs, max_length=max_source_length, padding=False, truncation=False)\n",
    "            input_wo_label = input_wo_label[\"input_ids\"]\n",
    "            model_inputs[\"metadata\"] = []\n",
    "            for idx in range(len(targets)):\n",
    "                model_inputs[\"metadata\"].append(\n",
    "                    {\n",
    "                        \"targets\": targets[idx],\n",
    "                        \"input_len\": len(input_wo_label[idx]),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'My body cast a shadow over the grass.', 'choice1': 'The sun was rising.', 'choice2': 'The grass was cut.', 'question': 'cause', 'idx': 0, 'label': 0}\n",
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'dict'>\n",
      "{'premise': 'My body cast a shadow over the grass.', 'choice1': 'The sun was rising.', 'choice2': 'The grass was cut.', 'question': 'cause', 'idx': 0, 'label': 0, 'source_text': 'COPA (Choice of Plausible Alternatives): Given a premise, a question (cause/effect) and two alternative choices, identify plausible answer from the alternative choices.  premise: My body cast a shadow over the grass. question: cause choice1: The sun was rising. choice2: The grass was cut.Select answer from: choice1,choice2. Answer:', 'target_text': 'choice1'}\n",
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"super_glue\", \"copa\")\n",
    "raw_datasets, postprocess_fn = peft_comparison.text2text_utils.dataset_to_text2text(\n",
    "    raw_datasets,\n",
    "    task_type=\"classification\",\n",
    "    dataset_name=\"copa\",\n",
    "    decoder_only=True,\n",
    ")\n",
    "column_names = raw_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'My body cast a shadow over the grass.',\n",
       " 'choice1': 'The sun was rising.',\n",
       " 'choice2': 'The grass was cut.',\n",
       " 'question': 'cause',\n",
       " 'idx': 0,\n",
       " 'label': 0,\n",
       " 'source_text': 'COPA (Choice of Plausible Alternatives): Given a premise, a question (cause/effect) and two alternative choices, identify plausible answer from the alternative choices.  premise: My body cast a shadow over the grass. question: cause choice1: The sun was rising. choice2: The grass was cut.Select answer from: choice1,choice2. Answer:',\n",
       " 'target_text': 'choice1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Running tokenizer on val dataset  \",\n",
    "    fn_kwargs={\"is_eval\": True, \"decoder_only\": decoder_only},\n",
    ")\n",
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=min(5000, len(raw_datasets[\"train\"]) // 8),\n",
    "    num_proc=8,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    "    fn_kwargs={\"decoder_only\": decoder_only},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForCausalLMWithMetadata(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8,\n",
    "    max_length=max_source_length,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=2)\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=data_collator, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 104])\n",
      "<s> COPA (Choice of Plausible Alternatives): Given a premise, a question (cause/effect) and two alternative choices, identify plausible answer from the alternative choices.  premise: The man begged for forgiveness. question: effect choice1: The woman took pity on him. choice2: The woman joked around with him.Select answer from: choice1,choice2. Answer:<s> choice1</s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "<s> COPA (Choice of Plausible Alternatives): Given a premise, a question (cause/effect) and two alternative choices, identify plausible answer from the alternative choices.  premise: The security guard replayed the surveillance footage. question: cause choice1: The surveillance camera was out of focus. choice2: He noticed some suspicious activity.Select answer from: choice1,choice2. Answer:<s> choice2</s></s></s></s></s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/public/vdeshpan/miniconda3/envs/peft_comparison_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    t_ = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=False)\n",
    "    for ex in t_:\n",
    "        print(ex)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = batch[\"attention_mask\"][0, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"][0, s_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in eval_dataloader:\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    t_ = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=False)\n",
    "    for ex in t_:\n",
    "        print(ex)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft_comparison_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
