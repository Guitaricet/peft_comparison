{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names_mapping = {\n",
    "    # taken from, \n",
    "    # glue: https://github.com/tensorflow/datasets/blob/1e12611a0be5f4753d271d7eb1dde15eb8f0185c/docs/community_catalog/huggingface/glue.md\n",
    "    # super_glue: https://github.com/tensorflow/datasets/blob/1e12611a0be5f4753d271d7eb1dde15eb8f0185c/docs/community_catalog/huggingface/super_glue.md\n",
    "    \"cola\": [\n",
    "        \"unacceptable\",\n",
    "        \"acceptable\"\n",
    "    ],\n",
    "    \"mnli\": [\n",
    "        \"entailment\",\n",
    "        \"neutral\",\n",
    "        \"contradiction\"\n",
    "    ],\n",
    "    \"mrpc\": [\n",
    "        \"not_equivalent\",\n",
    "        \"equivalent\"\n",
    "    ],\n",
    "    \"qnli\": [\n",
    "        \"entailment\",\n",
    "        \"not_entailment\"\n",
    "    ],\n",
    "    \"qqp\": [\n",
    "        \"not_duplicate\",\n",
    "        \"duplicate\"\n",
    "    ],\n",
    "    \"rte\": [\n",
    "        \"entailment\",\n",
    "        \"not_entailment\"\n",
    "    ],\n",
    "    \"sst2\": [\n",
    "        \"negative\",\n",
    "        \"positive\"\n",
    "    ],\n",
    "    \"stsb\": None,\n",
    "    \"ax\": [\n",
    "        \"entailment\",\n",
    "        \"neutral\",\n",
    "        \"contradiction\"\n",
    "    ],\n",
    "    \"wnli\": [\n",
    "        \"not_entailment\",\n",
    "        \"entailment\"\n",
    "    ],\n",
    "    \"boolq\": [\n",
    "        \"False\",\n",
    "        \"True\"\n",
    "    ],\n",
    "    \"cb\": [\n",
    "        \"entailment\",\n",
    "        \"contradiction\",\n",
    "        \"neutral\"\n",
    "    ],\n",
    "    \"copa\": [\n",
    "        \"choice1\",\n",
    "        \"choice2\"\n",
    "    ],\n",
    "    \"multirc\": [\n",
    "        \"False\",\n",
    "        \"True\"\n",
    "    ],\n",
    "    \"record\": None,\n",
    "    \"wic\": [\n",
    "        \"False\",\n",
    "        \"True\"\n",
    "    ],\n",
    "    \"wsc\": [\n",
    "        \"False\",\n",
    "        \"True\"\n",
    "    ],\n",
    "    \"wsc.fixed\": [\n",
    "        \"False\",\n",
    "        \"True\"\n",
    "    ],\n",
    "    \"axb\": [\n",
    "        \"entailment\",\n",
    "        \"not_entailment\"\n",
    "    ],\n",
    "    \"axg\": [\n",
    "        \"entailment\",\n",
    "        \"not_entailment\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_glue_one_example(x, benchmark_name, label_names, feature_names=None, id_key='idx'):\n",
    "    \"\"\"\n",
    "\n",
    "    CODE SOURCE: https://github.com/google-research/text-to-text-transfer-transformer/blob/24d9d3b89b129e586bbfe35cffbc5926d88adc5e/t5/data/preprocessors.py#L734C1-L812C12\n",
    "    \n",
    "    Convert a dataset from glue to text2text examples.\n",
    "\n",
    "    This function uses the feature names from the dataset to unpack examples into\n",
    "    a format amenable for a text2text problem. For example, consider the Quora\n",
    "    Question Pairs (QQP) benchmark, which would suggest\n",
    "    benchmark_name=\"qqp\"\n",
    "    label_names=['not_duplicate', 'duplicate']\n",
    "    For QQP, a typical example might look like\n",
    "    {\n",
    "        \"question1\": \"Why do I easily get bored of my friends?\",\n",
    "        \"question2\": \"Why do I get bored of friends so quickly?\",\n",
    "        \"label\": 1,\n",
    "        \"idx\": 10,\n",
    "    }\n",
    "\n",
    "    This example would be transformed to\n",
    "    {\n",
    "        \"inputs\": (\n",
    "            \"qqp question1: Why do I easily get bored of my friends? question2: \"\n",
    "            \"Why do I get bored of my friends so quickly?\"\n",
    "        ),\n",
    "        \"targets\": \"duplicate\",\n",
    "        \"idx\": 10,\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "    x: an example to process.\n",
    "    benchmark_name: the name of the GLUE benchmark for this dataset.\n",
    "    label_names: a list of label names corresponding to class index.\n",
    "    feature_names: an optional ordered list of feature names. If provided,\n",
    "        features will be ordered in this way in the output. If not provided, all\n",
    "        features (except 'idx' and 'label') will be used, sorted by name.\n",
    "    id_key: str, key for id in the dataset. If not provided, 'idx' will be used.\n",
    "        if None, no id will be added to the dataset.\n",
    "\n",
    "    Returns:\n",
    "    A preprocessed example.\n",
    "    \"\"\"\n",
    "    # If an ordering is not provided, sort feature keys to ensure a consistent\n",
    "    # order.\n",
    "    feature_keys = (\n",
    "        feature_names or sorted(set(x.keys()).difference(['label', 'idx'])))\n",
    "    # Pack keys (formatted as \" key: \") and corresponding text feature\n",
    "    strs_to_join = []\n",
    "    for key in feature_keys:\n",
    "        strs_to_join.append('{}:'.format(key))\n",
    "        strs_to_join.append(str(x[key]))\n",
    "    # Add benchmark name at the start\n",
    "    strs_to_join.insert(0, benchmark_name)\n",
    "\n",
    "    # label name\n",
    "    if x['label'] == -1:\n",
    "        label_name = \"<unk>\"\n",
    "    else:\n",
    "        label_name = label_names[x[\"label\"]]\n",
    "\n",
    "    ex = {}\n",
    "    joined = \" \".join(strs_to_join)\n",
    "    if benchmark_name == 'multirc':\n",
    "        # Remove HTML markup.\n",
    "        joined = re.sub(r\"<br>\", \" \", joined)\n",
    "        joined = re.sub(r\"<(/)?b>\", \"\", joined)\n",
    "\n",
    "        # Store the data index in the returned example (used by eval)\n",
    "        ex['idx/paragraph'] = x['idx']['paragraph']\n",
    "        ex['idx/question'] = x['idx']['question']\n",
    "        ex['idx/answer'] = x['idx']['answer']\n",
    "    else:\n",
    "        # Store the data index in the returned example (used by eval)\n",
    "        if id_key:\n",
    "            ex['idx'] = x[id_key]\n",
    "\n",
    "    ex['inputs'] = joined\n",
    "    ex['targets'] = label_name\n",
    "\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  33.  43.  63. 106. 247.]\n",
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import datasets\n",
    "\n",
    "#\n",
    "dataset_config_name = \"rte\"\n",
    "raw_datasets = load_dataset(\"super_glue\", dataset_config_name)\n",
    "label_names = label_names_mapping[dataset_config_name]\n",
    "train_dataset = []\n",
    "for instance in raw_datasets[\"train\"]:\n",
    "    instance_dict = preprocess_glue_one_example(\n",
    "        x=instance,\n",
    "        benchmark_name=dataset_config_name, \n",
    "        label_names=label_names,\n",
    "    )\n",
    "    train_dataset.append(instance_dict)\n",
    "train_dataset = datasets.Dataset.from_list(train_dataset)\n",
    "\n",
    "eval_dataset = []\n",
    "for instance in raw_datasets[\"validation\"]:\n",
    "    instance_dict = preprocess_glue_one_example(\n",
    "        x=instance,\n",
    "        benchmark_name=dataset_config_name, \n",
    "        label_names=label_names,\n",
    "    )\n",
    "    eval_dataset.append(instance_dict)\n",
    "eval_dataset = datasets.Dataset.from_list(eval_dataset)\n",
    "\n",
    "test_dataset = []\n",
    "for instance in raw_datasets[\"test\"]:\n",
    "    instance_dict = preprocess_glue_one_example(\n",
    "        x=instance,\n",
    "        benchmark_name=dataset_config_name, \n",
    "        label_names=label_names,\n",
    "    )\n",
    "    test_dataset.append(instance_dict)\n",
    "test_dataset = datasets.Dataset.from_list(test_dataset)\n",
    "\n",
    "#\n",
    "len_inputs = [i[\"inputs\"].split(\" \").__len__() for i in train_dataset] + [i[\"inputs\"].split(\" \").__len__() for i in eval_dataset] + [i[\"inputs\"].split(\" \").__len__() for i in test_dataset]\n",
    "len_targets = [i[\"targets\"].split(\" \").__len__() for i in train_dataset] + [i[\"targets\"].split(\" \").__len__() for i in eval_dataset] + [i[\"targets\"].split(\" \").__len__() for i in test_dataset]\n",
    "\n",
    "#\n",
    "print(np.percentile(len_inputs, [0, 25, 50, 75, 90, 100]))\n",
    "print(np.percentile(len_targets, [0, 25, 50, 75, 90, 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 4,\n",
       " 'inputs': \"rte hypothesis: Paul Stewart Hutchinson is accused of having stabbed a girl. premise: A man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on BBC One's Crimewatch. Colette Aram, 16, was walking to her boyfriend's house in Keyworth, Nottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a field close to her home. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates later.\",\n",
       " 'targets': 'not_entailment'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long_seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
